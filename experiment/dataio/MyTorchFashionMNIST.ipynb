{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "# from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "labels_dict = {\n",
        "    0: 'T-shirt/top',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle boot'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St2VDfojBfZG",
        "outputId": "5ac139fe-d89b-42c6-ebb6-45a72c639243"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLzUjRjErXT3",
        "outputId": "31db157f-0283-48e7-ac25-8592fad42426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The train set contains 60000 images, in 469 batches\n",
            "The test set contains 10000 images, in 79 batches\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"The train set contains {} images, in {} batches\".format(len(train_dataloader.dataset), len(train_dataloader)))\n",
        "# print(\"The validation set contains {} images, in {} batches\".format(len(valid_loader.dataset), len(valid_loader)))\n",
        "print(\"The test set contains {} images, in {} batches\".format(len(test_dataloader.dataset), len(test_dataloader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXsRg8cWrb0b",
        "outputId": "9cdf9872-82fc-4eb7-d048-ac1710d65b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from logging import log\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu = nn.Sequential(\n",
        "        nn.Linear(28*28, 256),\n",
        "        nn.ReLU(),       \n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64,10),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu(x)\n",
        "    return logits\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "print(model)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# loss_fn = nn.SoftMarginLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.85)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "J7Atj3fCrsBL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    X,y = X.to(device), y.to(device)\n",
        "\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0,0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X,y in dataloader:\n",
        "      X,y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sjums5-Er3Ie",
        "outputId": "6b680640-c4e2-49ac-9df8-49422403809e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.305113 [    0/60000]\n",
            "loss: 2.255174 [12800/60000]\n",
            "loss: 1.156485 [25600/60000]\n",
            "loss: 0.810770 [38400/60000]\n",
            "loss: 0.691693 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.7%, Avg loss: 0.752694 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.603482 [    0/60000]\n",
            "loss: 0.553010 [12800/60000]\n",
            "loss: 0.546334 [25600/60000]\n",
            "loss: 0.551934 [38400/60000]\n",
            "loss: 0.583819 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.8%, Avg loss: 0.568236 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.418007 [    0/60000]\n",
            "loss: 0.422120 [12800/60000]\n",
            "loss: 0.434360 [25600/60000]\n",
            "loss: 0.458837 [38400/60000]\n",
            "loss: 0.480729 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.509917 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.338948 [    0/60000]\n",
            "loss: 0.381669 [12800/60000]\n",
            "loss: 0.362062 [25600/60000]\n",
            "loss: 0.413312 [38400/60000]\n",
            "loss: 0.431055 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 0.483687 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.297949 [    0/60000]\n",
            "loss: 0.359991 [12800/60000]\n",
            "loss: 0.322419 [25600/60000]\n",
            "loss: 0.389820 [38400/60000]\n",
            "loss: 0.391641 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.454522 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.265494 [    0/60000]\n",
            "loss: 0.321170 [12800/60000]\n",
            "loss: 0.294870 [25600/60000]\n",
            "loss: 0.367579 [38400/60000]\n",
            "loss: 0.358311 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.438715 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.245685 [    0/60000]\n",
            "loss: 0.295405 [12800/60000]\n",
            "loss: 0.292620 [25600/60000]\n",
            "loss: 0.340594 [38400/60000]\n",
            "loss: 0.341168 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.426830 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.226053 [    0/60000]\n",
            "loss: 0.269906 [12800/60000]\n",
            "loss: 0.292457 [25600/60000]\n",
            "loss: 0.320408 [38400/60000]\n",
            "loss: 0.316788 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.0%, Avg loss: 0.413575 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.219108 [    0/60000]\n",
            "loss: 0.255339 [12800/60000]\n",
            "loss: 0.297610 [25600/60000]\n",
            "loss: 0.303667 [38400/60000]\n",
            "loss: 0.299965 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.401120 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.196294 [    0/60000]\n",
            "loss: 0.249068 [12800/60000]\n",
            "loss: 0.298508 [25600/60000]\n",
            "loss: 0.287150 [38400/60000]\n",
            "loss: 0.294607 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.384445 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.175184 [    0/60000]\n",
            "loss: 0.240399 [12800/60000]\n",
            "loss: 0.302117 [25600/60000]\n",
            "loss: 0.280170 [38400/60000]\n",
            "loss: 0.287007 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.380532 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.167544 [    0/60000]\n",
            "loss: 0.231309 [12800/60000]\n",
            "loss: 0.298691 [25600/60000]\n",
            "loss: 0.273421 [38400/60000]\n",
            "loss: 0.271873 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.379248 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.161383 [    0/60000]\n",
            "loss: 0.219168 [12800/60000]\n",
            "loss: 0.281027 [25600/60000]\n",
            "loss: 0.260885 [38400/60000]\n",
            "loss: 0.270597 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.376782 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.155547 [    0/60000]\n",
            "loss: 0.218412 [12800/60000]\n",
            "loss: 0.296764 [25600/60000]\n",
            "loss: 0.268671 [38400/60000]\n",
            "loss: 0.268782 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.376880 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.147845 [    0/60000]\n",
            "loss: 0.225994 [12800/60000]\n",
            "loss: 0.282501 [25600/60000]\n",
            "loss: 0.253367 [38400/60000]\n",
            "loss: 0.254297 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.377002 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.149608 [    0/60000]\n",
            "loss: 0.214434 [12800/60000]\n",
            "loss: 0.282916 [25600/60000]\n",
            "loss: 0.230422 [38400/60000]\n",
            "loss: 0.245569 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.389398 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.150824 [    0/60000]\n",
            "loss: 0.214499 [12800/60000]\n",
            "loss: 0.286761 [25600/60000]\n",
            "loss: 0.227556 [38400/60000]\n",
            "loss: 0.233908 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.382802 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.138258 [    0/60000]\n",
            "loss: 0.212129 [12800/60000]\n",
            "loss: 0.275497 [25600/60000]\n",
            "loss: 0.220012 [38400/60000]\n",
            "loss: 0.218704 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.380443 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.140414 [    0/60000]\n",
            "loss: 0.222112 [12800/60000]\n",
            "loss: 0.272387 [25600/60000]\n",
            "loss: 0.216525 [38400/60000]\n",
            "loss: 0.213886 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.383876 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.142393 [    0/60000]\n",
            "loss: 0.212475 [12800/60000]\n",
            "loss: 0.286740 [25600/60000]\n",
            "loss: 0.201962 [38400/60000]\n",
            "loss: 0.208155 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.380632 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.133596 [    0/60000]\n",
            "loss: 0.209206 [12800/60000]\n",
            "loss: 0.298375 [25600/60000]\n",
            "loss: 0.204936 [38400/60000]\n",
            "loss: 0.183014 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.384879 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.133008 [    0/60000]\n",
            "loss: 0.197639 [12800/60000]\n",
            "loss: 0.271759 [25600/60000]\n",
            "loss: 0.183761 [38400/60000]\n",
            "loss: 0.170675 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.378173 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.122276 [    0/60000]\n",
            "loss: 0.194054 [12800/60000]\n",
            "loss: 0.260421 [25600/60000]\n",
            "loss: 0.203654 [38400/60000]\n",
            "loss: 0.166572 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.404156 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.133081 [    0/60000]\n",
            "loss: 0.204153 [12800/60000]\n",
            "loss: 0.271547 [25600/60000]\n",
            "loss: 0.185329 [38400/60000]\n",
            "loss: 0.185609 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.408674 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.127869 [    0/60000]\n",
            "loss: 0.177078 [12800/60000]\n",
            "loss: 0.255951 [25600/60000]\n",
            "loss: 0.163858 [38400/60000]\n",
            "loss: 0.183911 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.393290 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.102933 [    0/60000]\n",
            "loss: 0.173154 [12800/60000]\n",
            "loss: 0.257538 [25600/60000]\n",
            "loss: 0.167130 [38400/60000]\n",
            "loss: 0.154537 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.398173 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.104955 [    0/60000]\n",
            "loss: 0.170186 [12800/60000]\n",
            "loss: 0.223324 [25600/60000]\n",
            "loss: 0.174131 [38400/60000]\n",
            "loss: 0.161492 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.396963 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.106844 [    0/60000]\n",
            "loss: 0.171588 [12800/60000]\n",
            "loss: 0.219052 [25600/60000]\n",
            "loss: 0.165103 [38400/60000]\n",
            "loss: 0.152153 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.424423 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.102170 [    0/60000]\n",
            "loss: 0.177265 [12800/60000]\n",
            "loss: 0.217559 [25600/60000]\n",
            "loss: 0.156662 [38400/60000]\n",
            "loss: 0.147857 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.418879 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.096122 [    0/60000]\n",
            "loss: 0.160156 [12800/60000]\n",
            "loss: 0.210621 [25600/60000]\n",
            "loss: 0.154047 [38400/60000]\n",
            "loss: 0.144708 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.414800 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.086389 [    0/60000]\n",
            "loss: 0.172046 [12800/60000]\n",
            "loss: 0.265599 [25600/60000]\n",
            "loss: 0.161479 [38400/60000]\n",
            "loss: 0.147355 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.436753 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.086367 [    0/60000]\n",
            "loss: 0.139531 [12800/60000]\n",
            "loss: 0.214592 [25600/60000]\n",
            "loss: 0.143428 [38400/60000]\n",
            "loss: 0.133295 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.447251 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.087455 [    0/60000]\n",
            "loss: 0.135103 [12800/60000]\n",
            "loss: 0.207933 [25600/60000]\n",
            "loss: 0.138513 [38400/60000]\n",
            "loss: 0.148915 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.436214 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.085240 [    0/60000]\n",
            "loss: 0.158535 [12800/60000]\n",
            "loss: 0.194570 [25600/60000]\n",
            "loss: 0.149663 [38400/60000]\n",
            "loss: 0.123755 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.458576 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.083212 [    0/60000]\n",
            "loss: 0.145865 [12800/60000]\n",
            "loss: 0.203789 [25600/60000]\n",
            "loss: 0.143432 [38400/60000]\n",
            "loss: 0.171721 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.430277 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.090181 [    0/60000]\n",
            "loss: 0.121510 [12800/60000]\n",
            "loss: 0.199466 [25600/60000]\n",
            "loss: 0.137867 [38400/60000]\n",
            "loss: 0.108051 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.457492 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.086034 [    0/60000]\n",
            "loss: 0.135323 [12800/60000]\n",
            "loss: 0.201474 [25600/60000]\n",
            "loss: 0.120330 [38400/60000]\n",
            "loss: 0.146782 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.470921 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.086328 [    0/60000]\n",
            "loss: 0.120705 [12800/60000]\n",
            "loss: 0.206480 [25600/60000]\n",
            "loss: 0.118928 [38400/60000]\n",
            "loss: 0.099070 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.464171 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.104110 [    0/60000]\n",
            "loss: 0.160472 [12800/60000]\n",
            "loss: 0.221547 [25600/60000]\n",
            "loss: 0.116822 [38400/60000]\n",
            "loss: 0.096998 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.475972 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.091542 [    0/60000]\n",
            "loss: 0.145001 [12800/60000]\n",
            "loss: 0.184063 [25600/60000]\n",
            "loss: 0.128142 [38400/60000]\n",
            "loss: 0.081590 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.483778 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 40\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hOUccyFtZy7",
        "outputId": "69ac1bf7-7c28-4afd-ceb3-3d5eefb64185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained and saved.\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'fashion_mnist_model.pth')\n",
        "\n",
        "print('Model trained and saved.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "asW2ZcUdtqNO",
        "outputId": "43e807ca-38e8-4c28-93df-000fd05a2959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n",
            "Predicted digit: 0\n",
            "Fashion: T-shirt/top\n",
            "model:\n",
            "Net(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "dir(model):\n",
            "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'flatten', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'linear_relu', 'load_state_dict', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model = Net().to(device)\n",
        "model.load_state_dict(torch.load('fashion_mnist_model.pth', weights_only=True))\n",
        "model.eval()\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "image_path = 'z.png'\n",
        "image = Image.open(image_path).convert('L')\n",
        "# image = ImageOps.invert(image_inv)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((28, 28))\n",
        "])\n",
        "image = transform(image).to(device)\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "\n",
        "\n",
        "# Make a prediction \n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    prediction = torch.argmax(output).item()\n",
        "\n",
        "    print(f'Predicted digit: {prediction}')\n",
        "    print(f\"Fashion: {labels_dict[prediction]}\")\n",
        "    print(\"model:\\n{}\".format(model))\n",
        "    print(\"dir(model):\\n{}\".format(dir(model)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "cursoMLconda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
